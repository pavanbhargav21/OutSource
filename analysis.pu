
from fastapi import APIRouter
from .databricks_pool import DatabricksSession
from fastapi.responses import JSONResponse

router = APIRouter()

@router.get("/api/leadsummary")
async def get_lead_summary():
    with DatabricksSession(api_name="leadsummary") as conn:
        with conn.cursor() as cursor:
            cursor.execute("SELECT * FROM leads")
            result = cursor.fetchall()
    
    return JSONResponse(content={"data": result})

@router.get("/api/userstats")
async def get_user_stats():
    with DatabricksSession(api_name="userstats") as conn:
        with conn.cursor() as cursor:
            cursor.execute("SELECT * FROM users")
            result = cursor.fetchall()
    
    return JSONResponse(content={"data": result})

@router.get("/api/attendance")
async def get_attendance():
    with DatabricksSession(api_name="attendance") as conn:
        with conn.cursor() as cursor:
            cursor.execute("SELECT * FROM attendance")
            result = cursor.fetchall()
    
    return JSONResponse(content={"data": result})



import logging
import time
from queue import Queue, Empty
from databricks import sql
import os
from datetime import datetime

# Configuration
POOL_SIZE = 10
CONNECTION_TTL = 1800  # 30 minutes
connection_pool = Queue(maxsize=POOL_SIZE)

logger = logging.getLogger(__name__)

# Global stats - will be reset on stale detection
pool_stats = {
    'total_requests': 0,
    'new_connections': 0,
    'pool_hits': 0,
    'pool_misses': 0,
    'stale_resets': 0,
    'current_reset_start_time': time.time()
}

def create_connection():
    """Create a new Databricks connection"""
    server_hostname = os.environ.get('DATABRICKS_SERVER_HOSTNAME')
    http_path = os.environ.get('DATABRICKS_HTTP_PATH')
    
    return sql.connect(
        server_hostname=server_hostname,
        http_path=http_path,
        # ... your authentication config
    )

def reset_everything():
    """COMPLETE RESET: Close all connections and reset all counters"""
    # Close all connections in pool
    closed_count = 0
    while not connection_pool.empty():
        try:
            conn, _ = connection_pool.get_nowait()
            try:
                conn.close()
                closed_count += 1
            except:
                pass
        except Empty:
            break
    
    # RESET ALL COUNTERS to zero
    global pool_stats
    pool_stats = {
        'total_requests': 0,
        'new_connections': 0,
        'pool_hits': 0,
        'pool_misses': 0,
        'stale_resets': pool_stats['stale_resets'] + 1,
        'current_reset_start_time': time.time()
    }
    
    # CLEAR VISUAL SEPARATOR with timestamp and meaningful message
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    logger.info("")
    logger.info("🔁" * 60)
    logger.info(f"🔄 COMPLETE CONNECTION RESET at {timestamp}")
    logger.info(f"📊 Closed {closed_count} old connections")
    logger.info(f"🔄 All counters reset to ZERO - Fresh start!")
    logger.info(f"📈 This is reset #{pool_stats['stale_resets']}")
    logger.info("🔁" * 60)
    logger.info("")
    
    return closed_count

class DatabricksSession:
    """Connection pool with clear reset messages"""
    
    def __init__(self, api_name="unknown"):
        self.api_name = api_name
        self.connection_source = None
    
    def __enter__(self):
        # Try to get from pool first
        try:
            self.conn, self.last_used = connection_pool.get_nowait()
            self.connection_source = "pool"
            pool_stats['pool_hits'] += 1
            
            # Check if connection is stale - COMPLETE RESET if stale!
            if time.time() - self.last_used > CONNECTION_TTL:
                try:
                    self.conn.close()
                except:
                    pass
                
                # COMPLETE RESET with clear visual message
                reset_everything()
                
                # Create fresh connection
                self.conn = create_connection()
                self.connection_source = "new_after_reset"
                pool_stats['new_connections'] += 1
            
        except Empty:
            # Create new connection
            self.conn = create_connection()
            self.connection_source = "new"
            self.last_used = time.time()
            pool_stats['new_connections'] += 1
            pool_stats['pool_misses'] += 1
        
        return self.conn

    def __exit__(self, exc_type, exc_val, exc_tb):
        pool_stats['total_requests'] += 1
        current_pool_size = connection_pool.qsize()
        uptime_since_reset = time.time() - pool_stats['current_reset_start_time']
        
        # Calculate hit rate since last reset
        hit_rate = (pool_stats['pool_hits'] / pool_stats['total_requests'] * 100) if pool_stats['total_requests'] > 0 else 0
        
        # Meaningful log message with emojis for quick scanning
        logger.info(
            f"📡 {self.api_name} → {self.connection_source} "
            f"| 🏊 pool:{current_pool_size}/{POOL_SIZE} "
            f"| 📊 Req:{pool_stats['total_requests']} "
            f"| 🆕 New:{pool_stats['new_connections']} "
            f"| ✅ Hit:{pool_stats['pool_hits']} "
            f"| 🔄 Resets:{pool_stats['stale_resets']} "
            f"| 🎯 Rate:{hit_rate:.1f}% "
            f"| ⏰ {uptime_since_reset:.0f}s"
        )
        
        # Return to pool if it's a fresh connection
        try:
            if not connection_pool.full():
                connection_pool.put((self.conn, time.time()))
            else:
                self.conn.close()
        except Exception:
            try:
                self.conn.close()
            except:
                pass



Subject: Urgent: Fix for Databricks Connection Memory Issues Causing Worker Crashes

Hi Team,

I'm sharing a detailed analysis of the memory issues that caused our workers to crash, along with the complete solution. Please read this carefully as it affects our production stability.

🔍 What Happened: Worker Crash Analysis

From our logs:

```
WORKER TIMEOUT (pid:1120)
Worker (pid:1121) was sent SIGKILL! Perhaps out of memory
Worker (pid:1125) was sent SIGKILL! Perhaps out of memory
```

Root Cause: Our Databricks connection pool was consuming excessive memory, triggering the OS Out-of-Memory (OOM) killer to terminate workers.

🧠 The Perfect Storm: How We Got Here

1. Async Workers Misunderstanding

We're using Uvicorn async workers, which can handle 100+ requests concurrently per worker. This is great for performance but dangerous for memory.

2. Memory Math That Broke Us

```python
# OLD DANGEROUS SETUP:
WORKERS_PER_INSTANCE = 8
POOL_SIZE = 10
MEMORY_PER_CONNECTION = 75MB  # Databricks connections are heavy

# Calculation:
8 workers × 10 connections × 75MB = 6,000MB = 6GB
+ Python runtime: 500MB
+ Application: 200MB
+ Gunicorn: 300MB
+ OS: 500MB
---
TOTAL: 7.5GB+ ← Exceeded our container limits!
```

3. Async Multiplication Effect

Since each async worker handles 100+ requests, but we thought it was 1 request per worker:

· We expected: 8 workers × 1 request = 8 connections
· Reality: 8 workers × 100 requests × 10 pool size = 8,000 potential connections!

📊 The Technical Breakdown

Sync vs Async Workers:

 Sync Workers Async Workers
Requests per worker 1 100+
Connection needs Low Very High
Memory risk Low Very High

Our Mistaken Assumption:

We configured connection pools as if each worker only handled one request, but with async workers, each worker handles many requests simultaneously.

🚀 The Complete Solution

1. New Safe Configuration

```python
# databricks_pool.py
POOL_SIZE = 3  # ↓ FROM 10 to 3 (70% reduction)
CONNECTION_TTL = 1800  # 30-minute reset

# gunicorn command
gunicorn -w 2 -k uvicorn.workers.UvicornWorker app:app  # ↓ FROM 8 to 2 workers
```

2. Memory Monitoring Added

```python
import psutil
import logging

def check_memory():
    """Monitor memory usage and prevent OOM kills"""
    memory = psutil.virtual_memory()
    if memory.percent > 80:
        logging.warning(f"🚨 High memory: {memory.percent}%")
        # Automatic safety measures can be added
```

3. Async-Aware Connection Limiting

```python
from asyncio import Semaphore

# Limit concurrent Databricks queries per instance
MAX_CONCURRENT_QUERIES = 20
query_semaphore = Semaphore(MAX_CONCURRENT_QUERIES)

@app.get("/api/endpoint")
async def api_endpoint():
    async with query_semaphore:  # ← Prevents async overload
        with DatabricksSession(api_name="endpoint") as conn:
            # ... your query
```

📈 New Safe Memory Math

```python
# NEW SAFE SETUP:
INSTANCES = 6
WORKERS_PER_INSTANCE = 2    # ↓ From 8
POOL_SIZE = 3               # ↓ From 10
MEMORY_PER_CONNECTION = 75MB

# Total connections: 6 instances × 3 connections = 18 connections
# Memory usage: 18 × 75MB = 1.35GB ← Manageable!

# Concurrent requests: 6 instances × 2 workers × 100 async = 1,200 requests!
```

🎯 Why This Works:

1. Shared Pool Understanding: Connection pool is per instance, not per worker
2. Async Awareness: We now account for async concurrency in our calculations
3. Memory Safety: Drastic reduction in potential memory usage
4. Monitoring: Early warning system for memory issues

🔧 Implementation Plan

Phase 1: Immediate Fix (Today)

```python
# 1. Reduce pool size to 3
POOL_SIZE = 3

# 2. Reduce workers to 2 per instance
gunicorn -w 2 -k uvicorn.workers.UvicornWorker app:app

# 3. Add memory monitoring
```

Phase 2: Enhanced Protection (Next Week)

· Add automatic connection reduction during high memory
· Implement circuit breaker for Databricks
· Add detailed metrics and alerts

Phase 3: Optimization (Ongoing)

· Fine-tune based on actual usage metrics
· Implement connection pooling with health checks
· Add retry mechanisms with backoff

📊 Expected Results

Before:

```
🚨 WORKER TIMEOUT (pid:1120)
🚨 Worker was sent SIGKILL! Perhaps out of memory
```

After:

```
✅ CONN_EXIT: leadsummary → pool (pool:2/3) Req:150 New:12 Hit:138
✅ CONN_EXIT: userstats → pool (pool:3/3) Req:151 New:12 Hit:139
```

🚨 Monitoring Checklist

1. Memory usage below 80%
2. No OOM kills in logs
3. Pool hit rate above 90%
4. Databricks response times stable
5. No HTTP 429 (throttling) errors

💡 Key Takeaways

1. Async workers multiply connection needs - they handle many requests concurrently
2. Connection pools are shared per instance - not per worker
3. Databricks connections are memory-heavy - ~75MB each
4. We must configure for worst-case scenarios - not ideal cases

🆘 When to Escalate

If you see:

· Memory usage consistently above 85%
· Frequent OOM kills despite changes
· Databricks throttling (HTTP 429)
· Response times increasing dramatically

This fix should resolve our stability issues while maintaining performance. The changes are deployed and monitoring is in place.

Best regards,
[Your Name]
[Your Position]

P.S. This wasn't a code error but a configuration misunderstanding of how async workers interact with connection pooling. The solution makes us both stable and more efficient!