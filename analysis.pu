
from fastapi import APIRouter
from .databricks_pool import DatabricksSession
from fastapi.responses import JSONResponse

router = APIRouter()

@router.get("/api/leadsummary")
async def get_lead_summary():
    with DatabricksSession(api_name="leadsummary") as conn:
        with conn.cursor() as cursor:
            cursor.execute("SELECT * FROM leads")
            result = cursor.fetchall()
    
    return JSONResponse(content={"data": result})

@router.get("/api/userstats")
async def get_user_stats():
    with DatabricksSession(api_name="userstats") as conn:
        with conn.cursor() as cursor:
            cursor.execute("SELECT * FROM users")
            result = cursor.fetchall()
    
    return JSONResponse(content={"data": result})

@router.get("/api/attendance")
async def get_attendance():
    with DatabricksSession(api_name="attendance") as conn:
        with conn.cursor() as cursor:
            cursor.execute("SELECT * FROM attendance")
            result = cursor.fetchall()
    
    return JSONResponse(content={"data": result})



import logging
import time
from queue import Queue, Empty
from databricks import sql
import os
from datetime import datetime

# Configuration
POOL_SIZE = 10
CONNECTION_TTL = 1800  # 30 minutes
connection_pool = Queue(maxsize=POOL_SIZE)

logger = logging.getLogger(__name__)

# Global stats - will be reset on stale detection
pool_stats = {
    'total_requests': 0,
    'new_connections': 0,
    'pool_hits': 0,
    'pool_misses': 0,
    'stale_resets': 0,
    'current_reset_start_time': time.time()
}

def create_connection():
    """Create a new Databricks connection"""
    server_hostname = os.environ.get('DATABRICKS_SERVER_HOSTNAME')
    http_path = os.environ.get('DATABRICKS_HTTP_PATH')
    
    return sql.connect(
        server_hostname=server_hostname,
        http_path=http_path,
        # ... your authentication config
    )

def reset_everything():
    """COMPLETE RESET: Close all connections and reset all counters"""
    # Close all connections in pool
    closed_count = 0
    while not connection_pool.empty():
        try:
            conn, _ = connection_pool.get_nowait()
            try:
                conn.close()
                closed_count += 1
            except:
                pass
        except Empty:
            break
    
    # RESET ALL COUNTERS to zero
    global pool_stats
    pool_stats = {
        'total_requests': 0,
        'new_connections': 0,
        'pool_hits': 0,
        'pool_misses': 0,
        'stale_resets': pool_stats['stale_resets'] + 1,
        'current_reset_start_time': time.time()
    }
    
    # CLEAR VISUAL SEPARATOR with timestamp and meaningful message
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    logger.info("")
    logger.info("ğŸ”" * 60)
    logger.info(f"ğŸ”„ COMPLETE CONNECTION RESET at {timestamp}")
    logger.info(f"ğŸ“Š Closed {closed_count} old connections")
    logger.info(f"ğŸ”„ All counters reset to ZERO - Fresh start!")
    logger.info(f"ğŸ“ˆ This is reset #{pool_stats['stale_resets']}")
    logger.info("ğŸ”" * 60)
    logger.info("")
    
    return closed_count

class DatabricksSession:
    """Connection pool with clear reset messages"""
    
    def __init__(self, api_name="unknown"):
        self.api_name = api_name
        self.connection_source = None
    
    def __enter__(self):
        # Try to get from pool first
        try:
            self.conn, self.last_used = connection_pool.get_nowait()
            self.connection_source = "pool"
            pool_stats['pool_hits'] += 1
            
            # Check if connection is stale - COMPLETE RESET if stale!
            if time.time() - self.last_used > CONNECTION_TTL:
                try:
                    self.conn.close()
                except:
                    pass
                
                # COMPLETE RESET with clear visual message
                reset_everything()
                
                # Create fresh connection
                self.conn = create_connection()
                self.connection_source = "new_after_reset"
                pool_stats['new_connections'] += 1
            
        except Empty:
            # Create new connection
            self.conn = create_connection()
            self.connection_source = "new"
            self.last_used = time.time()
            pool_stats['new_connections'] += 1
            pool_stats['pool_misses'] += 1
        
        return self.conn

    def __exit__(self, exc_type, exc_val, exc_tb):
        pool_stats['total_requests'] += 1
        current_pool_size = connection_pool.qsize()
        uptime_since_reset = time.time() - pool_stats['current_reset_start_time']
        
        # Calculate hit rate since last reset
        hit_rate = (pool_stats['pool_hits'] / pool_stats['total_requests'] * 100) if pool_stats['total_requests'] > 0 else 0
        
        # Meaningful log message with emojis for quick scanning
        logger.info(
            f"ğŸ“¡ {self.api_name} â†’ {self.connection_source} "
            f"| ğŸŠ pool:{current_pool_size}/{POOL_SIZE} "
            f"| ğŸ“Š Req:{pool_stats['total_requests']} "
            f"| ğŸ†• New:{pool_stats['new_connections']} "
            f"| âœ… Hit:{pool_stats['pool_hits']} "
            f"| ğŸ”„ Resets:{pool_stats['stale_resets']} "
            f"| ğŸ¯ Rate:{hit_rate:.1f}% "
            f"| â° {uptime_since_reset:.0f}s"
        )
        
        # Return to pool if it's a fresh connection
        try:
            if not connection_pool.full():
                connection_pool.put((self.conn, time.time()))
            else:
                self.conn.close()
        except Exception:
            try:
                self.conn.close()
            except:
                pass



Subject: Urgent: Fix for Databricks Connection Memory Issues Causing Worker Crashes

Hi Team,

I'm sharing a detailed analysis of the memory issues that caused our workers to crash, along with the complete solution. Please read this carefully as it affects our production stability.

ğŸ” What Happened: Worker Crash Analysis

From our logs:

```
WORKER TIMEOUT (pid:1120)
Worker (pid:1121) was sent SIGKILL! Perhaps out of memory
Worker (pid:1125) was sent SIGKILL! Perhaps out of memory
```

Root Cause: Our Databricks connection pool was consuming excessive memory, triggering the OS Out-of-Memory (OOM) killer to terminate workers.

ğŸ§  The Perfect Storm: How We Got Here

1. Async Workers Misunderstanding

We're using Uvicorn async workers, which can handle 100+ requests concurrently per worker. This is great for performance but dangerous for memory.

2. Memory Math That Broke Us

```python
# OLD DANGEROUS SETUP:
WORKERS_PER_INSTANCE = 8
POOL_SIZE = 10
MEMORY_PER_CONNECTION = 75MB  # Databricks connections are heavy

# Calculation:
8 workers Ã— 10 connections Ã— 75MB = 6,000MB = 6GB
+ Python runtime: 500MB
+ Application: 200MB
+ Gunicorn: 300MB
+ OS: 500MB
---
TOTAL: 7.5GB+ â† Exceeded our container limits!
```

3. Async Multiplication Effect

Since each async worker handles 100+ requests, but we thought it was 1 request per worker:

Â· We expected: 8 workers Ã— 1 request = 8 connections
Â· Reality: 8 workers Ã— 100 requests Ã— 10 pool size = 8,000 potential connections!

ğŸ“Š The Technical Breakdown

Sync vs Async Workers:

 Sync Workers Async Workers
Requests per worker 1 100+
Connection needs Low Very High
Memory risk Low Very High

Our Mistaken Assumption:

We configured connection pools as if each worker only handled one request, but with async workers, each worker handles many requests simultaneously.

ğŸš€ The Complete Solution

1. New Safe Configuration

```python
# databricks_pool.py
POOL_SIZE = 3  # â†“ FROM 10 to 3 (70% reduction)
CONNECTION_TTL = 1800  # 30-minute reset

# gunicorn command
gunicorn -w 2 -k uvicorn.workers.UvicornWorker app:app  # â†“ FROM 8 to 2 workers
```

2. Memory Monitoring Added

```python
import psutil
import logging

def check_memory():
    """Monitor memory usage and prevent OOM kills"""
    memory = psutil.virtual_memory()
    if memory.percent > 80:
        logging.warning(f"ğŸš¨ High memory: {memory.percent}%")
        # Automatic safety measures can be added
```

3. Async-Aware Connection Limiting

```python
from asyncio import Semaphore

# Limit concurrent Databricks queries per instance
MAX_CONCURRENT_QUERIES = 20
query_semaphore = Semaphore(MAX_CONCURRENT_QUERIES)

@app.get("/api/endpoint")
async def api_endpoint():
    async with query_semaphore:  # â† Prevents async overload
        with DatabricksSession(api_name="endpoint") as conn:
            # ... your query
```

ğŸ“ˆ New Safe Memory Math

```python
# NEW SAFE SETUP:
INSTANCES = 6
WORKERS_PER_INSTANCE = 2    # â†“ From 8
POOL_SIZE = 3               # â†“ From 10
MEMORY_PER_CONNECTION = 75MB

# Total connections: 6 instances Ã— 3 connections = 18 connections
# Memory usage: 18 Ã— 75MB = 1.35GB â† Manageable!

# Concurrent requests: 6 instances Ã— 2 workers Ã— 100 async = 1,200 requests!
```

ğŸ¯ Why This Works:

1. Shared Pool Understanding: Connection pool is per instance, not per worker
2. Async Awareness: We now account for async concurrency in our calculations
3. Memory Safety: Drastic reduction in potential memory usage
4. Monitoring: Early warning system for memory issues

ğŸ”§ Implementation Plan

Phase 1: Immediate Fix (Today)

```python
# 1. Reduce pool size to 3
POOL_SIZE = 3

# 2. Reduce workers to 2 per instance
gunicorn -w 2 -k uvicorn.workers.UvicornWorker app:app

# 3. Add memory monitoring
```

Phase 2: Enhanced Protection (Next Week)

Â· Add automatic connection reduction during high memory
Â· Implement circuit breaker for Databricks
Â· Add detailed metrics and alerts

Phase 3: Optimization (Ongoing)

Â· Fine-tune based on actual usage metrics
Â· Implement connection pooling with health checks
Â· Add retry mechanisms with backoff

ğŸ“Š Expected Results

Before:

```
ğŸš¨ WORKER TIMEOUT (pid:1120)
ğŸš¨ Worker was sent SIGKILL! Perhaps out of memory
```

After:

```
âœ… CONN_EXIT: leadsummary â†’ pool (pool:2/3) Req:150 New:12 Hit:138
âœ… CONN_EXIT: userstats â†’ pool (pool:3/3) Req:151 New:12 Hit:139
```

ğŸš¨ Monitoring Checklist

1. Memory usage below 80%
2. No OOM kills in logs
3. Pool hit rate above 90%
4. Databricks response times stable
5. No HTTP 429 (throttling) errors

ğŸ’¡ Key Takeaways

1. Async workers multiply connection needs - they handle many requests concurrently
2. Connection pools are shared per instance - not per worker
3. Databricks connections are memory-heavy - ~75MB each
4. We must configure for worst-case scenarios - not ideal cases

ğŸ†˜ When to Escalate

If you see:

Â· Memory usage consistently above 85%
Â· Frequent OOM kills despite changes
Â· Databricks throttling (HTTP 429)
Â· Response times increasing dramatically

This fix should resolve our stability issues while maintaining performance. The changes are deployed and monitoring is in place.

Best regards,
[Your Name]
[Your Position]

P.S. This wasn't a code error but a configuration misunderstanding of how async workers interact with connection pooling. The solution makes us both stable and more efficient!