

Yes! You need to implement retry logic at the API level. The retry should happen for the entire Databricks query operation, not just the connection. Here's exactly what to do:

üìÅ api_endpoints.py (With Retry Logic)

Before (No Retry):

```python
@router.get("/api/leadsummary")
async def get_lead_summary():
    with DatabricksSession(api_name="leadsummary") as conn:
        with conn.cursor() as cursor:
            cursor.execute("SELECT * FROM leads")
            result = cursor.fetchall()
    
    return {"data": result}
```

After (With Retry):

```python
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception
import time

# Configure retry for all Databricks queries
@retry(
    stop=stop_after_attempt(3),  # Max 3 attempts
    wait=wait_exponential(multiplier=1, min=2, max=10),  # 2s, 4s, 8s delays
    retry=retry_if_exception(lambda e: isinstance(e, (TimeoutError, ConnectionError, Exception))),
    before_sleep=lambda retry_state: logger.warning(f"Retry #{retry_state.attempt_number} for {retry_state.fn.__name__}")
)
def execute_databricks_query(query, api_name):
    """Execute query with retry logic"""
    with DatabricksSession(api_name=api_name) as conn:
        with conn.cursor() as cursor:
            cursor.execute(query)
            return cursor.fetchall()

@router.get("/api/leadsummary")
async def get_lead_summary():
    start_time = time.time()
    try:
        result = execute_databricks_query("SELECT * FROM leads", "leadsummary")
        processing_time = time.time() - start_time
        logger.info(f"leadsummary succeeded in {processing_time:.2f}s")
        return {"data": result}
    except Exception as e:
        processing_time = time.time() - start_time
        logger.error(f"leadsummary failed after {processing_time:.2f}s: {str(e)}")
        return JSONResponse(
            status_code=500,
            content={"error": "Failed to fetch data after multiple retries"}
        )
```

üîß Alternative: Custom Retry Decorator

If you don't want to use tenacity library:

```python
import time
from functools import wraps

def retry_databricks_query(max_retries=3, initial_delay=2):
    """Custom retry decorator for Databricks queries"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            last_exception = None
            for attempt in range(max_retries):
                try:
                    return func(*args, **kwargs)
                except (TimeoutError, ConnectionError, Exception) as e:
                    last_exception = e
                    if attempt < max_retries - 1:  # Not last attempt
                        delay = initial_delay * (2 ** attempt)  # Exponential backoff
                        logger.warning(f"Attempt {attempt + 1} failed. Retrying in {delay}s: {str(e)}")
                        time.sleep(delay)
                    else:
                        logger.error(f"All {max_retries} attempts failed")
                        raise last_exception
            raise last_exception
        return wrapper
    return decorator

@retry_databricks_query(max_retries=3, initial_delay=2)
def execute_query_with_retry(query, api_name):
    """Execute query with custom retry logic"""
    with DatabricksSession(api_name=api_name) as conn:
        with conn.cursor() as cursor:
            cursor.execute(query)
            return cursor.fetchall()

@router.get("/api/leadsummary")
async def get_lead_summary():
    result = execute_query_with_retry("SELECT * FROM leads", "leadsummary")
    return {"data": result}
```

üéØ Where to Implement Retry Logic:

1. API Level (Recommended)

```python
# Retry the entire API operation including:
# - Connection acquisition
# - Query execution
# - Data fetching

@router.get("/api/data")
async def get_data():
    try:
        result = execute_with_retry("SELECT ...", "api_name")
        return {"data": result}
    except:
        return error_response
```

2. Service Level

```python
# Create a service layer that handles retries
class DataService:
    @retry(stop=stop_after_attempt(3))
    def get_lead_data(self):
        with DatabricksSession() as conn:
            # ... query logic

@router.get("/api/leadsummary")
async def get_lead_summary():
    service = DataService()
    result = service.get_lead_data()
    return {"data": result}
```

3. Connection Level (Already Done)

```python
# You already added retries in create_connection():
sql.connect(
    # ...
    retries=2,        # ‚Üê Connection-level retries
    retry_delay=1000
)
```

üìä Retry Strategy Configuration:

```python
# For different types of APIs, use different retry strategies:

# Fast APIs (should fail quickly):
@retry(stop=stop_after_attempt(2), wait=wait_fixed(1))

# Important APIs (more retries):
@retry(stop=stop_after_attempt(5), wait=wait_exponential(multiplier=1, min=2, max=30))

# Background jobs (persistent retries):
@retry(stop=stop_after_attempt(10), wait=wait_exponential(multiplier=2, min=5, max=120))
```

üöÄ Complete API Implementation:

```python
from fastapi import APIRouter, HTTPException
import time
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception

router = APIRouter()

# Global retry configuration
DATABRICKS_RETRY_CONFIG = {
    'stop': stop_after_attempt(3),
    'wait': wait_exponential(multiplier=1, min=2, max=10),
    'retry': retry_if_exception(lambda e: isinstance(e, (TimeoutError, ConnectionError))),
    'before_sleep': lambda retry_state: logger.warning(
        f"Retry #{retry_state.attempt_number} for {retry_state.fn.__name__}"
    )
}

@retry(**DATABRICKS_RETRY_CONFIG)
def execute_databricks_query(query, api_name):
    """Execute query with retry logic"""
    with DatabricksSession(api_name=api_name) as conn:
        with conn.cursor() as cursor:
            cursor.execute(query)
            return cursor.fetchall()

@router.get("/api/leadsummary")
async def get_lead_summary():
    start_time = time.time()
    try:
        result = execute_databricks_query(
            "SELECT * FROM leads WHERE date = CURRENT_DATE()", 
            "leadsummary"
        )
        processing_time = time.time() - start_time
        logger.info(f"leadsummary succeeded in {processing_time:.2f}s")
        return {"data": result}
        
    except Exception as e:
        processing_time = time.time() - start_time
        logger.error(f"leadsummary failed after {processing_time:.2f}s: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"Failed to fetch lead data after multiple attempts: {str(e)}"
        )

@router.get("/api/userstats")
async def get_user_stats():
    start_time = time.time()
    try:
        result = execute_databricks_query(
            "SELECT user_id, COUNT(*) FROM events GROUP BY user_id", 
            "userstats"
        )
        processing_time = time.time() - start_time
        logger.info(f"userstats succeeded in {processing_time:.2f}s")
        return {"data": result}
        
    except Exception as e:
        processing_time = time.time() - start_time
        logger.error(f"userstats failed after {processing_time:.2f}s: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"Failed to fetch user stats: {str(e)}"
        )
```

‚úÖ What This Achieves:

1. Automatic retries for transient failures
2. Exponential backoff to avoid overwhelming Databricks
3. Detailed logging for debugging
4. Proper error handling with HTTP status codes
5. Performance monitoring with timing information

The retry logic should be implemented at the API level to handle the complete operation from connection to query execution! üöÄ


____-_-_-&&--
from fastapi import APIRouter
from .databricks_pool import DatabricksSession
from fastapi.responses import JSONResponse

router = APIRouter()

@router.get("/api/leadsummary")
async def get_lead_summary():
    with DatabricksSession(api_name="leadsummary") as conn:
        with conn.cursor() as cursor:
            cursor.execute("SELECT * FROM leads")
            result = cursor.fetchall()
    
    return JSONResponse(content={"data": result})

@router.get("/api/userstats")
async def get_user_stats():
    with DatabricksSession(api_name="userstats") as conn:
        with conn.cursor() as cursor:
            cursor.execute("SELECT * FROM users")
            result = cursor.fetchall()
    
    return JSONResponse(content={"data": result})

@router.get("/api/attendance")
async def get_attendance():
    with DatabricksSession(api_name="attendance") as conn:
        with conn.cursor() as cursor:
            cursor.execute("SELECT * FROM attendance")
            result = cursor.fetchall()
    
    return JSONResponse(content={"data": result})



import logging
import time
from queue import Queue, Empty
from databricks import sql
import os
from datetime import datetime

# Configuration
POOL_SIZE = 10
CONNECTION_TTL = 1800  # 30 minutes
connection_pool = Queue(maxsize=POOL_SIZE)

logger = logging.getLogger(__name__)

# Global stats - will be reset on stale detection
pool_stats = {
    'total_requests': 0,
    'new_connections': 0,
    'pool_hits': 0,
    'pool_misses': 0,
    'stale_resets': 0,
    'current_reset_start_time': time.time()
}

def create_connection():
    """Create a new Databricks connection"""
    server_hostname = os.environ.get('DATABRICKS_SERVER_HOSTNAME')
    http_path = os.environ.get('DATABRICKS_HTTP_PATH')
    
    return sql.connect(
        server_hostname=server_hostname,
        http_path=http_path,
        # ... your authentication config
    )

def reset_everything():
    """COMPLETE RESET: Close all connections and reset all counters"""
    # Close all connections in pool
    closed_count = 0
    while not connection_pool.empty():
        try:
            conn, _ = connection_pool.get_nowait()
            try:
                conn.close()
                closed_count += 1
            except:
                pass
        except Empty:
            break
    
    # RESET ALL COUNTERS to zero
    global pool_stats
    pool_stats = {
        'total_requests': 0,
        'new_connections': 0,
        'pool_hits': 0,
        'pool_misses': 0,
        'stale_resets': pool_stats['stale_resets'] + 1,
        'current_reset_start_time': time.time()
    }
    
    # CLEAR VISUAL SEPARATOR with timestamp and meaningful message
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    logger.info("")
    logger.info("üîÅ" * 60)
    logger.info(f"üîÑ COMPLETE CONNECTION RESET at {timestamp}")
    logger.info(f"üìä Closed {closed_count} old connections")
    logger.info(f"üîÑ All counters reset to ZERO - Fresh start!")
    logger.info(f"üìà This is reset #{pool_stats['stale_resets']}")
    logger.info("üîÅ" * 60)
    logger.info("")
    
    return closed_count

class DatabricksSession:
    """Connection pool with clear reset messages"""
    
    def __init__(self, api_name="unknown"):
        self.api_name = api_name
        self.connection_source = None
    
    def __enter__(self):
        # Try to get from pool first
        try:
            self.conn, self.last_used = connection_pool.get_nowait()
            self.connection_source = "pool"
            pool_stats['pool_hits'] += 1
            
            # Check if connection is stale - COMPLETE RESET if stale!
            if time.time() - self.last_used > CONNECTION_TTL:
                try:
                    self.conn.close()
                except:
                    pass
                
                # COMPLETE RESET with clear visual message
                reset_everything()
                
                # Create fresh connection
                self.conn = create_connection()
                self.connection_source = "new_after_reset"
                pool_stats['new_connections'] += 1
            
        except Empty:
            # Create new connection
            self.conn = create_connection()
            self.connection_source = "new"
            self.last_used = time.time()
            pool_stats['new_connections'] += 1
            pool_stats['pool_misses'] += 1
        
        return self.conn

    def __exit__(self, exc_type, exc_val, exc_tb):
        pool_stats['total_requests'] += 1
        current_pool_size = connection_pool.qsize()
        uptime_since_reset = time.time() - pool_stats['current_reset_start_time']
        
        # Calculate hit rate since last reset
        hit_rate = (pool_stats['pool_hits'] / pool_stats['total_requests'] * 100) if pool_stats['total_requests'] > 0 else 0
        
        # Meaningful log message with emojis for quick scanning
        logger.info(
            f"üì° {self.api_name} ‚Üí {self.connection_source} "
            f"| üèä pool:{current_pool_size}/{POOL_SIZE} "
            f"| üìä Req:{pool_stats['total_requests']} "
            f"| üÜï New:{pool_stats['new_connections']} "
            f"| ‚úÖ Hit:{pool_stats['pool_hits']} "
            f"| üîÑ Resets:{pool_stats['stale_resets']} "
            f"| üéØ Rate:{hit_rate:.1f}% "
            f"| ‚è∞ {uptime_since_reset:.0f}s"
        )
        
        # Return to pool if it's a fresh connection
        try:
            if not connection_pool.full():
                connection_pool.put((self.conn, time.time()))
            else:
                self.conn.close()
        except Exception:
            try:
                self.conn.close()
            except:
                pass



Subject: Urgent: Fix for Databricks Connection Memory Issues Causing Worker Crashes

Hi Team,

I'm sharing a detailed analysis of the memory issues that caused our workers to crash, along with the complete solution. Please read this carefully as it affects our production stability.

üîç What Happened: Worker Crash Analysis

From our logs:

```
WORKER TIMEOUT (pid:1120)
Worker (pid:1121) was sent SIGKILL! Perhaps out of memory
Worker (pid:1125) was sent SIGKILL! Perhaps out of memory
```

Root Cause: Our Databricks connection pool was consuming excessive memory, triggering the OS Out-of-Memory (OOM) killer to terminate workers.

üß† The Perfect Storm: How We Got Here

1. Async Workers Misunderstanding

We're using Uvicorn async workers, which can handle 100+ requests concurrently per worker. This is great for performance but dangerous for memory.

2. Memory Math That Broke Us

```python
# OLD DANGEROUS SETUP:
WORKERS_PER_INSTANCE = 8
POOL_SIZE = 10
MEMORY_PER_CONNECTION = 75MB  # Databricks connections are heavy

# Calculation:
8 workers √ó 10 connections √ó 75MB = 6,000MB = 6GB
+ Python runtime: 500MB
+ Application: 200MB
+ Gunicorn: 300MB
+ OS: 500MB
---
TOTAL: 7.5GB+ ‚Üê Exceeded our container limits!
```

3. Async Multiplication Effect

Since each async worker handles 100+ requests, but we thought it was 1 request per worker:

¬∑ We expected: 8 workers √ó 1 request = 8 connections
¬∑ Reality: 8 workers √ó 100 requests √ó 10 pool size = 8,000 potential connections!

üìä The Technical Breakdown

Sync vs Async Workers:

 Sync Workers Async Workers
Requests per worker 1 100+
Connection needs Low Very High
Memory risk Low Very High

Our Mistaken Assumption:

We configured connection pools as if each worker only handled one request, but with async workers, each worker handles many requests simultaneously.

üöÄ The Complete Solution

1. New Safe Configuration

```python
# databricks_pool.py
POOL_SIZE = 3  # ‚Üì FROM 10 to 3 (70% reduction)
CONNECTION_TTL = 1800  # 30-minute reset

# gunicorn command
gunicorn -w 2 -k uvicorn.workers.UvicornWorker app:app  # ‚Üì FROM 8 to 2 workers
```

2. Memory Monitoring Added

```python
import psutil
import logging

def check_memory():
    """Monitor memory usage and prevent OOM kills"""
    memory = psutil.virtual_memory()
    if memory.percent > 80:
        logging.warning(f"üö® High memory: {memory.percent}%")
        # Automatic safety measures can be added
```

3. Async-Aware Connection Limiting

```python
from asyncio import Semaphore

# Limit concurrent Databricks queries per instance
MAX_CONCURRENT_QUERIES = 20
query_semaphore = Semaphore(MAX_CONCURRENT_QUERIES)

@app.get("/api/endpoint")
async def api_endpoint():
    async with query_semaphore:  # ‚Üê Prevents async overload
        with DatabricksSession(api_name="endpoint") as conn:
            # ... your query
```

üìà New Safe Memory Math

```python
# NEW SAFE SETUP:
INSTANCES = 6
WORKERS_PER_INSTANCE = 2    # ‚Üì From 8
POOL_SIZE = 3               # ‚Üì From 10
MEMORY_PER_CONNECTION = 75MB

# Total connections: 6 instances √ó 3 connections = 18 connections
# Memory usage: 18 √ó 75MB = 1.35GB ‚Üê Manageable!

# Concurrent requests: 6 instances √ó 2 workers √ó 100 async = 1,200 requests!
```

üéØ Why This Works:

1. Shared Pool Understanding: Connection pool is per instance, not per worker
2. Async Awareness: We now account for async concurrency in our calculations
3. Memory Safety: Drastic reduction in potential memory usage
4. Monitoring: Early warning system for memory issues

üîß Implementation Plan

Phase 1: Immediate Fix (Today)

```python
# 1. Reduce pool size to 3
POOL_SIZE = 3

# 2. Reduce workers to 2 per instance
gunicorn -w 2 -k uvicorn.workers.UvicornWorker app:app

# 3. Add memory monitoring
```

Phase 2: Enhanced Protection (Next Week)

¬∑ Add automatic connection reduction during high memory
¬∑ Implement circuit breaker for Databricks
¬∑ Add detailed metrics and alerts

Phase 3: Optimization (Ongoing)

¬∑ Fine-tune based on actual usage metrics
¬∑ Implement connection pooling with health checks
¬∑ Add retry mechanisms with backoff

üìä Expected Results

Before:

```
üö® WORKER TIMEOUT (pid:1120)
üö® Worker was sent SIGKILL! Perhaps out of memory
```

After:

```
‚úÖ CONN_EXIT: leadsummary ‚Üí pool (pool:2/3) Req:150 New:12 Hit:138
‚úÖ CONN_EXIT: userstats ‚Üí pool (pool:3/3) Req:151 New:12 Hit:139
```

üö® Monitoring Checklist

1. Memory usage below 80%
2. No OOM kills in logs
3. Pool hit rate above 90%
4. Databricks response times stable
5. No HTTP 429 (throttling) errors

üí° Key Takeaways

1. Async workers multiply connection needs - they handle many requests concurrently
2. Connection pools are shared per instance - not per worker
3. Databricks connections are memory-heavy - ~75MB each
4. We must configure for worst-case scenarios - not ideal cases

üÜò When to Escalate

If you see:

¬∑ Memory usage consistently above 85%
¬∑ Frequent OOM kills despite changes
¬∑ Databricks throttling (HTTP 429)
¬∑ Response times increasing dramatically

This fix should resolve our stability issues while maintaining performance. The changes are deployed and monitoring is in place.

Best regards,
[Your Name]
[Your Position]

P.S. This wasn't a code error but a configuration misunderstanding of how async workers interact with connection pooling. The solution makes us both stable and more efficient!